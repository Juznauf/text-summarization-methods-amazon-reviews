{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing and read in files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = r\"D:\\User\\Documents\\SMU CONTENT\\Year 3 Sem 2\\IS450\\Project\\Main\\Exploration\"\n",
    "os.chdir(workspace)\n",
    "path = r'TM_LDA_coherence200+.csv'\n",
    "topicData = pd.read_csv(path)\n",
    "df1 = pd.DataFrame(topicData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_interest = ['ProductId', 'Original', 'Text', 'product_category', 'Automated_topic_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[columns_interest].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Original</th>\n",
       "      <th>Text</th>\n",
       "      <th>product_category</th>\n",
       "      <th>Automated_topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>'Cakes'</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>This brand is moist, tasty and closer to the t...</td>\n",
       "      <td>'Cakes'</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>Namaste products are the best in my opinion of...</td>\n",
       "      <td>'Cakes'</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>Try it</td>\n",
       "      <td>'Cakes'</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>You won't be disappointed</td>\n",
       "      <td>'Cakes'</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                           Original  \\\n",
       "0  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "1  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "2  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "3  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "4  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "\n",
       "                                                Text product_category  \\\n",
       "0  This is my family's favorite brand of wheat fr...          'Cakes'   \n",
       "1  This brand is moist, tasty and closer to the t...          'Cakes'   \n",
       "2  Namaste products are the best in my opinion of...          'Cakes'   \n",
       "3                                             Try it          'Cakes'   \n",
       "4                          You won't be disappointed          'Cakes'   \n",
       "\n",
       "  Automated_topic_id  \n",
       "0            quality  \n",
       "1              taste  \n",
       "2            quality  \n",
       "3            quality  \n",
       "4              taste  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the product category column values, additional '' marks are include, we want to remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_product_cat(category):\n",
    "    \"\"\"\n",
    "    clean product category columns\n",
    "    \"\"\"    \n",
    "    return category.rstrip(\"/'\").lstrip(\" '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['product_category'] = df2['product_category'].apply(clean_product_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.replace('<br />', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Text'] = df2['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Original</th>\n",
       "      <th>Text</th>\n",
       "      <th>product_category</th>\n",
       "      <th>Automated_topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>Cakes</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>This brand is moist, tasty and closer to the t...</td>\n",
       "      <td>Cakes</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>Namaste products are the best in my opinion of...</td>\n",
       "      <td>Cakes</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>Try it</td>\n",
       "      <td>Cakes</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000LKU03G</td>\n",
       "      <td>This is my family's favorite brand of wheat fr...</td>\n",
       "      <td>You won't be disappointed</td>\n",
       "      <td>Cakes</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId                                           Original  \\\n",
       "0  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "1  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "2  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "3  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "4  B000LKU03G  This is my family's favorite brand of wheat fr...   \n",
       "\n",
       "                                                Text product_category  \\\n",
       "0  This is my family's favorite brand of wheat fr...            Cakes   \n",
       "1  This brand is moist, tasty and closer to the t...            Cakes   \n",
       "2  Namaste products are the best in my opinion of...            Cakes   \n",
       "3                                             Try it            Cakes   \n",
       "4                          You won't be disappointed            Cakes   \n",
       "\n",
       "  Automated_topic_id  \n",
       "0            quality  \n",
       "1              taste  \n",
       "2            quality  \n",
       "3            quality  \n",
       "4              taste  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryLs = df2.groupby('product_category').count().sort_values(by = 'Text').index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False Eyelashes & Adhesives'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoryLs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "\n",
    "def create_df(data,product_cat = 'Canola'):\n",
    "    \"\"\"\n",
    "    returns a new df from product_cat\n",
    "    \"\"\"\n",
    "    df1 = data[data['product_category'] == product_cat].copy()\n",
    "    return df1\n",
    "\n",
    "\n",
    "def pre_process(topicDf):\n",
    "    \n",
    "    \"\"\"\n",
    "    given a topic df, will return a main set of hot terms, using pos-tagging\n",
    "    \"\"\"\n",
    "    counter = 0 # count number of passed rows\n",
    "    main_set = set()\n",
    "    text_ls = list(topicDf['Text'].values)\n",
    "    for text in text_ls: # for each comment\n",
    "        try:\n",
    "            tagsText = nltk.pos_tag(word_tokenize(text)) # tokenize first then postag\n",
    "            main_set.update([x[0].lower() for x in tagsText if (x[1] == 'NN' and len(x[0])>1)]) # only keep track of the nouns and words with length 2   \n",
    "        except:\n",
    "            continue\n",
    "    return main_set    \n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def applyValue(text, hotTopics):\n",
    "    \n",
    "    \"\"\"\n",
    "    submethod apply for main method text val\n",
    "    \"\"\"\n",
    "    \n",
    "    VALUE = 0\n",
    "    \n",
    "    text_token = word_tokenize(text)\n",
    "    text_token_lower = [text.lower() for text in text_token]\n",
    "    text_counter = Counter(text_token_lower)\n",
    "    for k,v in text_counter.items():\n",
    "        if k in hotTopics:\n",
    "            VALUE += v\n",
    "    return VALUE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def textVal(topicDf, hotTopics):\n",
    "    \n",
    "    \"\"\"\n",
    "    create 2 new df columns:\n",
    "    1. value of text\n",
    "    2. value/length ratio    \n",
    "    \"\"\"\n",
    "    topicDf['Text'] = topicDf['Text'].apply(str)\n",
    "    topicDf['textValue'] = topicDf['Text'].apply(applyValue, hotTopics = hotTopics)\n",
    "    topicDf['textValue/length'] = topicDf['textValue']/topicDf['Text'].str.len() # vectorize ratio\n",
    "    \n",
    "    return topicDf\n",
    "\n",
    "\n",
    "def summarizerOpt(topicDf, word_limit = 100):\n",
    "    \"\"\"\n",
    "    using a greedy approach, returns the generated summary\n",
    "    \"\"\"\n",
    "    \n",
    "    # sort df by col textValue/len\n",
    "    if len(topicDf) < 2:\n",
    "        text = topicDf['Text'].values[0]   # if only one comment then return the original comment\n",
    "    else:\n",
    "        sortedTopicDf = topicDf.sort_values(by = ['textValue/length'], ascending = False).copy()\n",
    "        resultLs = []\n",
    "        for i in range(len(sortedTopicDf)):\n",
    "            if len(sortedTopicDf.iloc[i]['Text'].split()) > word_limit or 'nan' in sortedTopicDf.iloc[i]['Text']:\n",
    "                continue\n",
    "            else:\n",
    "                resultLs += [i]\n",
    "                word_limit -= len(sortedTopicDf.iloc[i]['Text'].split())\n",
    "        text = ''\n",
    "        for i in sorted(resultLs):   # rank the sentence in the original rank and then form the summary\n",
    "            text += sortedTopicDf['Text'].values[i] + '. '   # join the sentences\n",
    "        if len(text) == 0:\n",
    "            text = sortedTopicDf.iloc[0]['Text'] # if greedy finds none return the first text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Def Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_summarizer_opt(data, categoryLs):\n",
    "    \"\"\"\n",
    "    using submethods, will generate summaries for each topic and will\n",
    "    return a dataframe with column {categoryID, topic, summary, originalText}\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_df = pd.DataFrame(columns = ['categoryID', 'topic', 'summary', 'originalText'])\n",
    "    for i in range(len(categoryLs)): \n",
    "        print(\"Currently summarising \", categoryLs[i])\n",
    "        try:\n",
    "            if i%20 == 0: #sleep after every 20 topics\n",
    "                time.sleep(1) #pause for 10 seconds\n",
    "            if i > 180:\n",
    "                time.sleep(1)\n",
    "            tempDf = create_df(data, categoryLs[i])\n",
    "            tempTopicLs = list(tempDf['Automated_topic_id'].unique())\n",
    "            for j in range(len(tempTopicLs)):\n",
    "                tempTopicDf = tempDf[tempDf['Automated_topic_id'] == tempTopicLs[j]].copy() # create df with just a single topic\n",
    "                tempTextLs = tempTopicDf['Text'].apply(str).tolist()\n",
    "                combined_text = '. '.join(tempTextLs)\n",
    "                tempHotTopics = pre_process(tempTopicDf)\n",
    "                summary_out = summarizerOpt(textVal(tempTopicDf, tempHotTopics))\n",
    "                summary_df = summary_df.append({'categoryID':categoryLs[i],'topic':tempTopicLs[j], 'summary':summary_out, 'originalText':combined_text}, ignore_index=True)\n",
    "        except:\n",
    "            print(\"Exception occured at category\", categoryLs[i])\n",
    "            continue\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently summarising  Sunflowers\n",
      "Currently summarising  False Eyelashes & Adhesives\n",
      "Currently summarising  Pastry Shells & Crusts\n",
      "Currently summarising  Basic Collars\n",
      "Currently summarising  Hot Dogs & Franks\n",
      "Currently summarising  Indoor Gardening & Hydroponics\n",
      "Currently summarising  Cranberry\n",
      "Currently summarising  Pasta & Sauces\n",
      "Currently summarising  Shiitake\n",
      "Currently summarising  Shortening\n",
      "Currently summarising  Cayenne\n",
      "Currently summarising  Vines\n",
      "Currently summarising  Breakfast Foods\n",
      "Currently summarising  Wrapping & Packaging\n",
      "Currently summarising  Cloves\n",
      "Currently summarising  Coffee Cups & Mugs\n",
      "Currently summarising  Apple Cider\n",
      "Currently summarising  Deli-Sliced Meats\n",
      "Currently summarising  Processed\n",
      "Currently summarising  Lilies\n",
      "Currently summarising  Stuffing Side Dishes\n",
      "Currently summarising  Apricots\n",
      "Currently summarising  Pappardelle\n",
      "Currently summarising  Allspice\n",
      "Currently summarising  Sirloin\n",
      "Currently summarising  Eggs & Egg Substitutes\n",
      "Currently summarising  Ice Cream Cones & Toppings\n",
      "Currently summarising  Stews\n",
      "Currently summarising  Miso\n",
      "Currently summarising  Pork\n",
      "Currently summarising  Coriander\n",
      "Currently summarising  Alfredo\n",
      "Currently summarising  Mackerel\n",
      "Currently summarising  Soy Nuts\n",
      "Currently summarising  Orzo\n",
      "Currently summarising  Water Chestnuts\n",
      "Currently summarising  Hamburger Buns\n",
      "Currently summarising  Celery Seed\n",
      "Currently summarising  Omega 3-6-9\n",
      "Currently summarising  Chèvre\n",
      "Currently summarising  Oyster\n",
      "Currently summarising  Asian\n",
      "Currently summarising  Ribeye\n",
      "Currently summarising  Fenugreek\n",
      "Currently summarising  Breadcrumbs & Seasoned Coatings\n",
      "Currently summarising  Body Washes\n",
      "Currently summarising  Tofu\n",
      "Currently summarising  Pepper & Peppercorns\n",
      "Currently summarising  Walnut\n",
      "Currently summarising  Adapters\n",
      "Currently summarising  Thyme\n",
      "Currently summarising  Fennel Seed\n",
      "Currently summarising  Steak Sauce\n",
      "Currently summarising  Cookie Assortments\n",
      "Currently summarising  Cumin\n",
      "Currently summarising  Cough Drops\n",
      "Currently summarising  Chorizo\n",
      "Currently summarising  Jasmine\n",
      "Currently summarising  Lemonade\n",
      "Currently summarising  Stuffed Grape Leaves\n",
      "Currently summarising  Pectin\n",
      "Currently summarising  Spice & Seasoning Gifts\n",
      "Currently summarising  Gravies\n",
      "Currently summarising  Dessert Syrups & Sauces\n",
      "Currently summarising  Dried Prunes\n",
      "Currently summarising  Dried Mixed Fruits\n",
      "Currently summarising  Stone Fruits\n",
      "Currently summarising  Soba\n",
      "Currently summarising  Black Truffle\n",
      "Currently summarising  Clams\n",
      "Currently summarising  Porcini\n",
      "Currently summarising  Brittle\n",
      "Currently summarising  Snack Cakes\n",
      "Currently summarising  Artichoke Hearts\n",
      "Currently summarising  Fortune\n",
      "Currently summarising  Caramel\n",
      "Currently summarising  Dried Mangoes\n",
      "Currently summarising  Home Brewing Starter Sets\n",
      "Currently summarising  Wasabi\n",
      "Currently summarising  Steaks\n",
      "Currently summarising  Cheddar\n",
      "Currently summarising  Preamps\n",
      "Currently summarising  Cup Holders\n",
      "Currently summarising  Walnuts\n",
      "Currently summarising  Vinegars\n",
      "Currently summarising  Meat & Seafood\n",
      "Currently summarising  Capellini\n",
      "Currently summarising  Dehydrated\n",
      "Currently summarising  Bamboo\n",
      "Currently summarising  Kidney Beans\n",
      "Currently summarising  Breadsticks\n",
      "Currently summarising  Savory\n",
      "Currently summarising  Carob & Cocoa\n",
      "Currently summarising  Foie Gras & Pâtés\n",
      "Currently summarising  Whey\n",
      "Currently summarising  Vegetable Juice\n",
      "Currently summarising  Halva\n",
      "Currently summarising  Beef\n",
      "Currently summarising  Ghee\n",
      "Currently summarising  Pumpkin Seeds\n",
      "Currently summarising  Dried Dates\n",
      "Currently summarising  Ground Pepper\n",
      "Currently summarising  Mixed Bouquets\n",
      "Currently summarising  Paprika\n",
      "Currently summarising  Lentils\n",
      "Currently summarising  Non-Dairy Coffee Creamers\n",
      "Currently summarising  Fruitcakes\n",
      "Currently summarising  Rice Milk\n",
      "Currently summarising  Dried Berries\n",
      "Currently summarising  Freeze-Dried Food\n",
      "Currently summarising  Applesauce\n",
      "Currently summarising  Cajun Seasoning\n",
      "Currently summarising  Nuts\n",
      "Currently summarising  Salmon\n",
      "Currently summarising  Bakery & Dessert Gifts\n",
      "Currently summarising  Ingredient Kits\n",
      "Currently summarising  Bully Sticks\n",
      "Currently summarising  Wild Game & Fowl\n",
      "Currently summarising  Small Appliance Parts & Accessories\n",
      "Currently summarising  Cocktail Mixers\n",
      "Currently summarising  Oils\n",
      "Currently summarising  Curry Powder\n",
      "Currently summarising  Caviars & Roes\n",
      "Currently summarising  Basmati\n",
      "Currently summarising  Cheese\n",
      "Currently summarising  Truffle\n",
      "Currently summarising  Potato Side Dishes\n",
      "Currently summarising  Dried Seaweed & Nori\n",
      "Currently summarising  Chowders\n",
      "Currently summarising  Dog Food\n",
      "Currently summarising  Poultry & Seafood\n",
      "Currently summarising  Hemp Seeds\n",
      "Currently summarising  Soy Sauce\n",
      "Currently summarising  Italian\n",
      "Currently summarising  Multivitamins\n",
      "Currently summarising  Pistachios\n",
      "Currently summarising  Sprinkles\n",
      "Currently summarising  Biscotti\n",
      "Currently summarising  Vinaigrette\n",
      "Currently summarising  Chili Sauce\n",
      "Currently summarising  Chia Seeds\n",
      "Currently summarising  Flours & Meals\n",
      "Currently summarising  Mixed Nuts\n",
      "Currently summarising  Seeds & Bulbs\n",
      "Currently summarising  Caramels\n",
      "Currently summarising  Snack & Trail Mixes\n",
      "Currently summarising  Rooibos\n",
      "Currently summarising  Wheat\n",
      "Currently summarising  Balsamic\n",
      "Currently summarising  Almond Butter\n",
      "Currently summarising  Rawhide\n",
      "Currently summarising  Packaged Meals & Side Dishes\n",
      "Currently summarising  Dried Grains & Rice\n",
      "Currently summarising  Chocolate Drink Mixes\n",
      "Currently summarising  Chili Powder\n",
      "Currently summarising  Butter\n",
      "Currently summarising  Food Bars\n",
      "Currently summarising  Pasta & Noodles\n",
      "Currently summarising  Snack Gifts\n",
      "Currently summarising  Corn\n",
      "Currently summarising  Quinoa\n",
      "Currently summarising  Drinks\n",
      "Currently summarising  Pantry Staples\n",
      "Currently summarising  Pork Rinds\n",
      "Currently summarising  Vegetables\n",
      "Currently summarising  Ciders\n",
      "Currently summarising  Miso Soups\n",
      "Currently summarising  Powdered\n",
      "Currently summarising  Popped\n",
      "Currently summarising  Sauces\n",
      "Currently summarising  Catnip\n",
      "Currently summarising  White\n",
      "Currently summarising  Sardines\n",
      "Currently summarising  Bonsai\n",
      "Currently summarising  Instant Breakfast Drinks\n",
      "Currently summarising  Nuts & Seeds\n",
      "Currently summarising  Graham Crackers\n",
      "Currently summarising  Microwave\n",
      "Currently summarising  Dried Fruits\n",
      "Currently summarising  Brown\n",
      "Currently summarising  Popcorn\n",
      "Currently summarising  Shirataki\n",
      "Currently summarising  Fruit Leather\n",
      "Currently summarising  Breakfast & Cereal Bars\n",
      "Currently summarising  Fruit Snacks\n",
      "Currently summarising  Freeze-Dried\n",
      "Currently summarising  Cakes\n",
      "Currently summarising  Soft Drink Mixes\n",
      "Currently summarising  Macaroni & Cheese\n",
      "Currently summarising  Pretzels\n",
      "Currently summarising  Weight Loss\n",
      "Currently summarising  Tea\n",
      "Currently summarising  Jerky\n",
      "Currently summarising  Flavor Syrups\n",
      "Currently summarising  Tortilla\n",
      "Currently summarising  Bones\n",
      "Currently summarising  Snacks\n",
      "Currently summarising  Fruit & Nut\n",
      "Currently summarising  Peanut Butter\n",
      "Currently summarising  Cocoa\n"
     ]
    }
   ],
   "source": [
    "summary_out = main_summarizer_opt(df2, categoryLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at an example summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  :(From the time I was a small child, my mother was an advocate of apple cider vinegar and honey for health. This apple cider vinegar is great for incorporation into one's beauty regimen or household use. There is a 5-digit code on top of the cap. Works wonders for dry itchy scalp. I don't believe I've ever used apple cider vinegar in food before, but it's great for hair. Sometimes I like it in water, a tsp/16oz. The mixture was done perfectly, No stinging taste, it's sort of mellow, yet has that flavor of vinegar you are looking for. \n",
      "\n",
      "Original Text:  So much better for the hot summer months than sugary lemonade. :(From the time I was a small child, my mother was an advocate of apple cider vinegar and honey for health. I would best describe the effects as very close to the good feeling you experience when you drink coffee. Let me preface this by saying I purchased it at a local health food store for about a dollar less. The mixture was done perfectly, No stinging taste, it's sort of mellow, yet has that flavor of vinegar you are looking for. I can pretty much promise you, that you will 'not' be disappointed if you buy it. I don't believe I've ever used apple cider vinegar in food before, but it's great for hair. Works wonders for dry itchy scalp. This product isn't just good in deviled eggs it's also good for you're health. Sometimes I like it in water, a tsp/16oz. It is also said to be alkalizing to the body, which is a plus. As far as we're concerned, this is just as good, and at a lower price. There is a 5-digit code on top of the cap. A really good product gets four stars, but to warrant five stars requires it to be \"the best of the best\" in our opinion. This apple cider vinegar is great for incorporation into one's beauty regimen or household use. I only consume organic, non-gmo foods so this is an excellent choice for those who care about what they eat and drink\n"
     ]
    }
   ],
   "source": [
    "print('Summary: ',summary_out['summary'].iloc[34], end='\\n\\n')\n",
    "print(\"Original Text: \",summary_out['originalText'].iloc[34])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_out.to_csv('POSopt_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NewEnv",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
